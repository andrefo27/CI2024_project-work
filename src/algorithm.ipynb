{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code implemented by Andrea Fontana\n",
    "# Politecnico di Torino, Computational Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "problem = np.load('../data/problem_4.npz')\n",
    "x = problem['x']\n",
    "y = problem['y']\n",
    "\n",
    "TRAIN_SIZE = 1\n",
    "\n",
    "# decide how many data to train the model (0.6 --> 60% of the data, 1 --> 100% of the data)\n",
    "train_size = int(x.shape[1] * TRAIN_SIZE)\n",
    "\n",
    "# From (n_features, n_samples) to (n_samples, n_features)\n",
    "x_train = x[:, :train_size].T\n",
    "\n",
    "# From 1D array to 2D array with one column: useful to calculate MSE\n",
    "# -1 is used to arrange the number of rows to have one column\n",
    "y_train = y[:train_size].reshape(-1, 1)\n",
    "\n",
    "if TRAIN_SIZE != 1.0:\n",
    "    x_val = x[:, train_size:].T\n",
    "    y_val = y[train_size:].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEST \"\"\"\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "if TRAIN_SIZE != 1.0:\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Node and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe functions help to avoid eager calculus of np.where\n",
    "# np.close absorb values similar to zero to avoid certain RunTimeWarning\n",
    "def safe_div(x, y):\n",
    "    if np.isclose(y, 0):\n",
    "        return np.nan\n",
    "    return x / y\n",
    "\n",
    "def safe_tan(x):\n",
    "    if np.isclose(np.cos(x), 0):\n",
    "        return np.nan\n",
    "    return np.tan(x)\n",
    "\n",
    "def safe_cot(x):\n",
    "    if np.isclose(np.sin(x), 0):\n",
    "        return np.nan\n",
    "    return np.cos(x) / np.sin(x)\n",
    "\n",
    "def safe_sqrt(x):\n",
    "    if x < 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(x)\n",
    "\n",
    "def safe_ln(x):\n",
    "    if x <= 0:\n",
    "        return np.nan\n",
    "    return np.log(x)\n",
    "\n",
    "def safe_arccot(x):\n",
    "    if np.isclose(x, 0):\n",
    "        return np.pi / 2\n",
    "    return np.arctan(1 / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many dependent variables\n",
    "INPUT_VARS = x_train.shape[1]\n",
    "TERMINAL_SET = [f'x{i}' for i in range(INPUT_VARS)]\n",
    "\n",
    "# Function Set F: Set of functions with metadata for arity and semantic constraints\n",
    "FUNCTION_METADATA = {\n",
    "    '+': {'arity': 2, 'func': lambda x, y: x + y},\n",
    "    '-': {'arity': 2, 'func': lambda x, y: x - y},\n",
    "    '*': {'arity': 2, 'func': lambda x, y: x * y},\n",
    "    '/': {'arity': 2, 'func': safe_div},\n",
    "\n",
    "    'sin': {'arity': 1, 'func': lambda x: np.sin(x)},\n",
    "    'cos': {'arity': 1, 'func': lambda x: np.cos(x)},\n",
    "    'tan': {'arity': 1, 'func': safe_tan},\n",
    "    'cot': {'arity': 1, 'func': safe_cot},\n",
    "\n",
    "    'sinh': {'arity': 1, 'func': lambda x: np.sinh(np.clip(x, -200, 200))},\n",
    "    'cosh': {'arity': 1, 'func': lambda x: np.cosh(np.clip(x, -200, 200))},\n",
    "    'tanh': {'arity': 1, 'func': lambda x: np.tanh(x)},\n",
    "\n",
    "    'sqrt': {'arity': 1, 'func': safe_sqrt},\n",
    "    'sqr': {'arity': 1, 'func': lambda x: np.power(np.clip(x, -1e+50, 1e+50), 2)},\n",
    "    'cube': {'arity': 1, 'func': lambda x: np.power(np.clip(x, -1e+20, 1e+20), 3)},\n",
    "\n",
    "    'ln': {'arity': 1, 'func': safe_ln},\n",
    "    'exp': {'arity': 1, 'func': lambda x: np.exp(np.clip(x, -100, 350))},\n",
    "\n",
    "    'arctan': {'arity': 1, 'func': lambda x: np.arctan(x)},\n",
    "    'arccot': {'arity': 1, 'func': safe_arccot}\n",
    "}\n",
    "\n",
    "FUNCTION_SET_UNARY = [key for key, meta in FUNCTION_METADATA.items() if meta['arity'] == 1]\n",
    "FUNCTION_SET_BINARY = [key for key, meta in FUNCTION_METADATA.items() if meta['arity'] == 2]\n",
    "FUNCTION_SET = list(FUNCTION_METADATA.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEST \"\"\"\n",
    "print(INPUT_VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.left is None and self.right is None\n",
    "\n",
    "    \n",
    "    # Return depth of the tree\n",
    "    def get_height(self):\n",
    "        if self.is_leaf():\n",
    "            return 1\n",
    "        if self.value in FUNCTION_SET_UNARY:\n",
    "            return 1 + self.left.get_height()\n",
    "        return 1 + max(self.left.get_height(), self.right.get_height())\n",
    "    \n",
    "    \n",
    "    # Return number of the nodes of the tree\n",
    "    def get_size(self):\n",
    "        if self.is_leaf():\n",
    "            return 1\n",
    "        if self.value in FUNCTION_SET_UNARY:\n",
    "            return 1 + self.left.get_size()\n",
    "        return 1 + self.left.get_size() + self.right.get_size()\n",
    "    \n",
    "    \n",
    "    # Return a List of all the Nodes (class Node) of the tree\n",
    "    def get_all_subtrees(self) -> List:\n",
    "        subtrees = [self]\n",
    "        if self.left:\n",
    "            subtrees.extend(self.left.get_all_subtrees())\n",
    "        if self.right:\n",
    "            subtrees.extend(self.right.get_all_subtrees())\n",
    "        return subtrees\n",
    "\n",
    "    \n",
    "    def find_parent_of(self, target_node, current_node=None):\n",
    "        if current_node is None:\n",
    "            current_node = self\n",
    "        if current_node.left == target_node or current_node.right == target_node:\n",
    "            return current_node\n",
    "        if current_node.left:\n",
    "            parent = self.find_parent_of(target_node, current_node.left)\n",
    "            if parent: return parent\n",
    "        if current_node.right:\n",
    "            parent = self.find_parent_of(target_node, current_node.right)\n",
    "            if parent: return parent\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def copy(self):\n",
    "        if self.is_leaf():\n",
    "            return Node(self.value)\n",
    "        if self.value in FUNCTION_SET_UNARY:\n",
    "            return Node(self.value, self.left.copy())\n",
    "        return Node(self.value, self.left.copy(), self.right.copy())\n",
    "    \n",
    "\n",
    "    # Batch processing: evaluation for all the points in the dataset\n",
    "    # - resulting array contains the prediction for each point of the dataset\n",
    "    def evaluate(self, input_vars: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "        if self.value in input_vars:\n",
    "            return input_vars[self.value]\n",
    "        if self.is_leaf():\n",
    "            try:\n",
    "                # np.full_like models the numeric value into an np.ndarray of the same dimension of terminal variables:\n",
    "                # - (x0 + 0.5) --> ([1, 2, 3] + [0.5, 0.5, 0.5])\n",
    "                return np.full_like(list(input_vars.values())[0], float(self.value))\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Unknown terminal value: {self.value}\")\n",
    "\n",
    "        func = FUNCTION_METADATA[self.value]['func']\n",
    "\n",
    "        # Unary operators\n",
    "        if self.value in FUNCTION_SET_UNARY:\n",
    "            left_val = self.left.evaluate(input_vars)\n",
    "            return func(left_val)\n",
    "        # Binary operators\n",
    "        else:  \n",
    "            left_val = self.left.evaluate(input_vars)\n",
    "            right_val = self.right.evaluate(input_vars)\n",
    "            return func(left_val, right_val)\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.value)\n",
    "        if self.value in FUNCTION_SET_UNARY:\n",
    "            return f\"{self.value}({self.left})\"\n",
    "        return f\"({self.left} {self.value} {self.right})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_constants_and_variables(node):\n",
    "    #Count constants and variables (with frequency) in a tree.\n",
    "    #Returns a dict with:\n",
    "    #  - 'constants': number of constants\n",
    "    #  - 'variables': total number of variables\n",
    "    #  - 'variable_freq': frequency of each variable (e.g., {'x0': 2, 'x1': 1})\n",
    "   \n",
    "    if node is None:\n",
    "        return {'constants': 0, 'variables': 0, 'variable_freq': {}}\n",
    "\n",
    "    counts = {'constants': 0, 'variables': 0, 'variable_freq': {}}\n",
    "\n",
    "    # If the node is a leaf\n",
    "    if node.is_leaf():\n",
    "        try:\n",
    "            # Try converting to float → constant\n",
    "            float(node.value)\n",
    "            counts['constants'] = 1\n",
    "        except ValueError:\n",
    "            # It's a variable (e.g., 'x0', 'x1', ...)\n",
    "            counts['variables'] = 1\n",
    "            counts['variable_freq'][node.value] = 1\n",
    "        return counts\n",
    "\n",
    "    # If the node has children → recursive aggregation\n",
    "    left_counts = count_constants_and_variables(node.left)\n",
    "    for key in ['constants', 'variables']:\n",
    "        counts[key] += left_counts[key]\n",
    "    for var, freq in left_counts['variable_freq'].items():\n",
    "        counts['variable_freq'][var] = counts['variable_freq'].get(var, 0) + freq\n",
    "\n",
    "    if node.right:\n",
    "        right_counts = count_constants_and_variables(node.right)\n",
    "        for key in ['constants', 'variables']:\n",
    "            counts[key] += right_counts[key]\n",
    "        for var, freq in right_counts['variable_freq'].items():\n",
    "            counts['variable_freq'][var] = counts['variable_freq'].get(var, 0) + freq\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(individual: Node, max_depth, current_depth=0) -> Node:\n",
    "    # Limits the depth of a tree to max_depth.\n",
    "    # If the depth is not reached, the function continues to call itself on the left and right children.\n",
    "    if not individual:\n",
    "        return None\n",
    "    \n",
    "    # We have reached the depth limit --> convert the Node in a leaf\n",
    "    if current_depth >= (max_depth - 1):\n",
    "        if random.random() < 0.5:\n",
    "            new_value = random.choice(TERMINAL_SET)\n",
    "        else:\n",
    "            new_value = str(random.uniform(-1, 1))\n",
    "        \n",
    "        return Node(new_value)\n",
    "\n",
    "    # We haven't reached the depth limit\n",
    "    if individual.left:\n",
    "        individual.left = prune_tree(individual.left, max_depth, current_depth + 1)\n",
    "    if individual.right:\n",
    "        individual.right = prune_tree(individual.right, max_depth, current_depth + 1)\n",
    "        \n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_tree(node: Node) -> Node:\n",
    "    if node.is_leaf():\n",
    "        return node\n",
    "    if node.left:\n",
    "        node.left = simplify_tree(node.left)\n",
    "    if node.right:\n",
    "        node.right = simplify_tree(node.right)\n",
    "\n",
    "    # ========================================\n",
    "    # Operator(constant) -> constant\n",
    "    # ========================================\n",
    "    if node.value in FUNCTION_SET_UNARY:\n",
    "        if node.left.is_leaf():\n",
    "            try:\n",
    "                # Performs the mathematical function on the child's value if it is a constant\n",
    "                val = float(node.left.value)\n",
    "                result = FUNCTION_METADATA[node.value]['func'](val)\n",
    "\n",
    "                if not np.isinf(result) and not np.isnan(result):\n",
    "                    return Node(str(result))\n",
    "\n",
    "            except (ValueError, TypeError):\n",
    "                # This is a terminal, you don't have to simplify\n",
    "                pass\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Existing simplification logic (Constant Folding, A+A, etc.)\n",
    "    # ==============================================================================\n",
    "    if node.value in FUNCTION_SET_BINARY:\n",
    "        try:\n",
    "            left_val = float(node.left.value)\n",
    "            right_val = float(node.right.value)\n",
    "            \n",
    "            if node.value == '+':\n",
    "                result = left_val + right_val\n",
    "            elif node.value == '-':\n",
    "                result = left_val - right_val\n",
    "            elif node.value == '*':\n",
    "                result = left_val * right_val\n",
    "            elif node.value == '/':\n",
    "                result = left_val / right_val if right_val != 0 else 1.0\n",
    "\n",
    "            if not np.isinf(result) and not np.isnan(result):\n",
    "                return Node(str(result))\n",
    "        except (ValueError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        # A + A = 2 * A\n",
    "        if node.value == '+' and str(node.left) == str(node.right):\n",
    "            return Node('*', Node('2'), node.left)\n",
    "        \n",
    "        # A * 1 = A,    1 * A = A\n",
    "        if node.value == '*' and (node.right.value == '1' or node.left.value == '1'):\n",
    "            if node.left.value == '1':\n",
    "                return node.right\n",
    "            else:\n",
    "                return node.left\n",
    "        \n",
    "        # A / 1 = A\n",
    "        if node.value == '/' and node.right.value == '1':\n",
    "            return node.left\n",
    "        \n",
    "        # A - A = 0\n",
    "        if node.value == '-' and str(node.left) == str(node.right):\n",
    "            return Node('0')\n",
    "        \n",
    "        # A + 0 = A,    0 + A = A\n",
    "        if node.value == '+':\n",
    "            if node.left.value == '0':\n",
    "                return node.right\n",
    "            if node.right.value == '0':\n",
    "                return node.left\n",
    "            \n",
    "        # A * 0 = 0,    0 * A = 0\n",
    "        if node.value == '*' and (node.left.value == '0' or node.right.value == '0'):\n",
    "            return Node('0')\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(individual, data_x, data_y):\n",
    "    size_penalty = 0\n",
    "    unbalanced_penalty = 0\n",
    "    ratio_penalty = 0\n",
    "    raw_mse = 0\n",
    "    \n",
    "    try:\n",
    "        # {'x0': [column 0 values], 'x1': [column 1 values]}\n",
    "        input_vars = {f'x{i}': data_x[:, i] for i in range(data_x.shape[1])}\n",
    "        y_pred = individual.evaluate(input_vars).reshape(-1, 1)\n",
    "\n",
    "        # Handling Infinite or NaN Values\n",
    "        # - sqrt(-1) OR log(0) --> np.nan\n",
    "        # - the tree will have inf fitness, very unlikely to be selected for subsequent generations\n",
    "        if np.any(np.isnan(y_pred)) or np.any(np.isinf(y_pred)):\n",
    "            return (float('inf'), float('inf'))\n",
    "        \n",
    "        # Disable RuntimeWarning if it cathces overflow\n",
    "        with np.errstate(over='ignore'):\n",
    "            raw_mse = np.mean((y_pred - data_y) ** 2)\n",
    "\n",
    "        # If the error itself is unstable, it penalizes the individual\n",
    "        if np.isinf(raw_mse) or np.isnan(raw_mse):\n",
    "            return (float('inf'), float('inf'))\n",
    "        \n",
    "        # Calculate the penalty based on the size of the tree, if it is very large\n",
    "        size = individual.get_size()\n",
    "        max_size = (10.5 * INPUT_VARS) // 3\n",
    "        if size > max_size:\n",
    "            size_penalty = (size - max_size) * 0.02\n",
    "\n",
    "        # If a terminal is not present in the tree, its frequency is 0\n",
    "        terminal_counts = count_constants_and_variables(individual)\n",
    "        all_terminal_freqs = [terminal_counts['variable_freq'].get(f'x{i}', 0) for i in range(INPUT_VARS)]\n",
    "\n",
    "        terminal_penalty = 10\n",
    "        for freq in all_terminal_freqs:\n",
    "            if freq == 0:  # missing terminal\n",
    "                terminal_penalty *= 5\n",
    "\n",
    "        if sum(all_terminal_freqs) > 0:\n",
    "            std_dev = np.std(all_terminal_freqs)\n",
    "            unbalanced_penalty = std_dev * 10 + terminal_penalty\n",
    "        else:\n",
    "            # Penalty for trees that do not contain variables (constant)\n",
    "            unbalanced_penalty = 100 + terminal_penalty            \n",
    "\n",
    "        # penalize solutions with a high constant:variable ratio\n",
    "        constants = terminal_counts['constants']\n",
    "        variables = terminal_counts['variables']\n",
    "        \n",
    "        if variables > 0:\n",
    "            ratio = constants / variables\n",
    "            if ratio > 1:\n",
    "                # The penalty is proportional to the ratio, with a significant basis\n",
    "                ratio_penalty = 10 * ratio\n",
    "\n",
    "        return (raw_mse + size_penalty + unbalanced_penalty + ratio_penalty, raw_mse)\n",
    "    except (ValueError, ZeroDivisionError, OverflowError):\n",
    "        return (float('inf'), float('inf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Population Generation (Grow and Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow method: generates trees with depth <= max_depth\n",
    "def grow(max_depth, current_depth=0):\n",
    "    if current_depth >= (max_depth - 1):\n",
    "        # Choose an input variable or a random number\n",
    "        if random.random() < 0.5: \n",
    "            return Node(str(random.uniform(-1, 1)))\n",
    "        else:\n",
    "            return Node(random.choice(TERMINAL_SET))\n",
    "    \n",
    "    # Randomly choose between Function, Terminal or Costant\n",
    "    r = random.random()\n",
    "    if r < 0.75:  # 70% function\n",
    "        choice = random.choice(FUNCTION_SET)\n",
    "    elif random.random() < 0.5:\n",
    "        choice = 'number'\n",
    "    else:\n",
    "        choice = 'variable'\n",
    "\n",
    "    if choice in FUNCTION_SET_BINARY:\n",
    "        return Node(choice, grow(max_depth, current_depth + 1), grow(max_depth, current_depth + 1))\n",
    "    elif choice in FUNCTION_SET_UNARY:\n",
    "        return Node(choice, grow(max_depth, current_depth + 1))\n",
    "    else:\n",
    "        if choice == 'number':\n",
    "            return Node(str(random.uniform(-1, 1)))\n",
    "        else:\n",
    "            return Node(random.choice(TERMINAL_SET))\n",
    "        \n",
    "\n",
    "# Full method: generates trees with depth = max_depth\n",
    "def full(max_depth, current_depth=0):\n",
    "    if current_depth >= (max_depth - 1):\n",
    "        if random.random() < 0.5:\n",
    "            return Node(str(random.uniform(-1, 1)))\n",
    "        else:\n",
    "            return Node(random.choice(TERMINAL_SET))\n",
    "    \n",
    "    func_choice = random.choice(FUNCTION_SET)\n",
    "\n",
    "    if func_choice in FUNCTION_SET_BINARY:\n",
    "        return Node(func_choice, full(max_depth, current_depth + 1), full(max_depth, current_depth + 1))\n",
    "    elif func_choice in FUNCTION_SET_UNARY:\n",
    "        return Node(func_choice, full(max_depth, current_depth + 1))\n",
    "    \n",
    "\n",
    "def generate_population(pop_size, max_depth, x_train, y_train):\n",
    "    population = []\n",
    "    num_grow = int(pop_size * 0.6)\n",
    "    num_full = pop_size - num_grow\n",
    "\n",
    "    for _ in range(num_grow):\n",
    "        individual = grow_and_simplify(max_depth, x_train, y_train)\n",
    "        population.append(individual)\n",
    "    for _ in range(num_full):\n",
    "        individual = full_and_simplify(max_depth, x_train, y_train)\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "\n",
    "# Wrapper function that generates a tree using the Grow method and simplifies it\n",
    "def grow_and_simplify(max_depth, x_train, y_train):\n",
    "    while True:\n",
    "        # Generate the tree\n",
    "        tree = grow(max_depth, current_depth=0)\n",
    "        # Apply simplification\n",
    "        simplified_tree = simplify_tree(tree)\n",
    "        # Calculate fitness to check validity\n",
    "        fitness, _ = calculate_fitness(simplified_tree, x_train, y_train)\n",
    "        \n",
    "        # If fitness is valid, exit the loop and return the tree\n",
    "        if not np.isnan(fitness) and not np.isinf(fitness):\n",
    "            return simplified_tree\n",
    "        \n",
    "\n",
    "# Wrapper function that generates a tree using the Full method and simplifies it\n",
    "def full_and_simplify(max_depth, x_train, y_train):\n",
    "    while True:\n",
    "        # Generate the tree\n",
    "        tree = full(max_depth, current_depth=0)\n",
    "        # Apply simplification\n",
    "        simplified_tree = simplify_tree(tree)\n",
    "        # Calculate fitness to check validity\n",
    "        fitness, _ = calculate_fitness(simplified_tree, x_train, y_train)\n",
    "        \n",
    "        # If fitness is valid, exit the loop and return the tree\n",
    "        if not np.isnan(fitness) and not np.isinf(fitness):\n",
    "            return simplified_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Genetic Operators (Crossover and Mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_crossover(parent1: Node, parent2: Node) -> tuple[Node, Node]:\n",
    "    # Two exact copies of the two parent trees are created.\n",
    "    child1 = parent1.copy()\n",
    "    child2 = parent2.copy()\n",
    "\n",
    "    # All the lists of nodes that make up each tree are generated\n",
    "    subtrees1 = child1.get_all_subtrees()\n",
    "    subtrees2 = child2.get_all_subtrees()\n",
    "\n",
    "    # Two nodes are chosen randomly, representing the roots of the sub-trees to be exchanged\n",
    "    subtree1_to_swap = random.choice(subtrees1)\n",
    "    subtree2_to_swap = random.choice(subtrees2)\n",
    "\n",
    "    # --- Editing child1 ---\n",
    "    if subtree1_to_swap == child1:  \n",
    "        # If the root is selected, the new tree is directly a copy of the other subtree.\n",
    "        child1 = subtree2_to_swap.copy()\n",
    "    else:\n",
    "        # Find the parent of the subtree to swap (parent_of_swap1)\n",
    "        parent_of_swap1 = child1.find_parent_of(subtree1_to_swap)\n",
    "        # Replaces the reference to the old subtree with a copy of the new subtree from the other parent.\n",
    "        if parent_of_swap1.left == subtree1_to_swap:\n",
    "            parent_of_swap1.left = subtree2_to_swap.copy()\n",
    "        else:\n",
    "            parent_of_swap1.right = subtree2_to_swap.copy()\n",
    "\n",
    "    # --- Editing child2 ---\n",
    "    if subtree2_to_swap == child2:\n",
    "        child2 = subtree1_to_swap.copy()\n",
    "    else:\n",
    "        parent_of_swap2 = child2.find_parent_of(subtree2_to_swap)\n",
    "        if parent_of_swap2.left == subtree2_to_swap:\n",
    "            parent_of_swap2.left = subtree1_to_swap.copy()\n",
    "        else:\n",
    "            parent_of_swap2.right = subtree1_to_swap.copy()\n",
    "    \n",
    "    return child1, child2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_mutation(parent, max_depth):\n",
    "    individual = parent.copy()\n",
    "    all_nodes = individual.get_all_subtrees()\n",
    "    \n",
    "    # Subtree Mutation: Replaces a subtree with a new tree\n",
    "    if len(all_nodes) > 1:\n",
    "        node_to_replace = random.choice(all_nodes[1:])\n",
    "    else:\n",
    "        node_to_replace = individual\n",
    "\n",
    "    new_subtree = grow_and_simplify(max_depth, x_train, y_train)\n",
    "\n",
    "    if node_to_replace == individual:\n",
    "        return new_subtree\n",
    "    parent_of_replace = individual.find_parent_of(node_to_replace)\n",
    "    if parent_of_replace.left == node_to_replace:\n",
    "        parent_of_replace.left = new_subtree\n",
    "    else:\n",
    "        parent_of_replace.right = new_subtree\n",
    "\n",
    "    return prune_tree(individual, max_depth)\n",
    "\n",
    "\n",
    "def point_mutation(parent, max_depth=None):\n",
    "    individual = parent.copy()\n",
    "    all_nodes = individual.get_all_subtrees()\n",
    "    \n",
    "    # Point Mutation: Replaces a single node with a new node of its same type\n",
    "    if not all_nodes:\n",
    "        return individual\n",
    "    \n",
    "    node_to_mutate = random.choice(all_nodes)\n",
    "\n",
    "    if node_to_mutate.is_leaf():\n",
    "        # The node is a leaf. Determines whether it is a constant or a variable.\n",
    "        try:\n",
    "            # Case 1: the node is a constant\n",
    "            float(node_to_mutate.value)\n",
    "            original_value = node_to_mutate.value\n",
    "            new_value = original_value\n",
    "            while new_value == original_value:\n",
    "                new_value = str(random.uniform(-1, 1))\n",
    "            node_to_mutate.value = new_value\n",
    "        except ValueError:\n",
    "            # Case 2: If the conversion fails, it is a variable\n",
    "            original_value = node_to_mutate.value\n",
    "            new_value = original_value\n",
    "            if len(TERMINAL_SET) > 1:\n",
    "                while new_value == original_value:\n",
    "                    new_value = random.choice(TERMINAL_SET)\n",
    "            else:\n",
    "                # Replace with a constant\n",
    "                new_value = str(random.uniform(-1, 1))\n",
    "            node_to_mutate.value = new_value\n",
    "    else:\n",
    "        # The node is an (internal) operator\n",
    "        if node_to_mutate.value in FUNCTION_SET_UNARY:\n",
    "            new_value = random.choice(FUNCTION_SET_UNARY)\n",
    "        else:\n",
    "            new_value = random.choice(FUNCTION_SET_BINARY)\n",
    "        node_to_mutate.value = new_value\n",
    "    \n",
    "    return individual\n",
    "\n",
    "\n",
    "def hoist_mutation(parent, max_depth=None):\n",
    "    individual = parent.copy()\n",
    "    all_nodes = individual.get_all_subtrees()\n",
    "    \n",
    "    # Hoist Mutation: Replaces the root with a random subtree\n",
    "    # Creates a list of all nodes within the tree that are not leaves or roots\n",
    "    internal_nodes = [n for n in all_nodes if not n.is_leaf() and n != individual]\n",
    "    if internal_nodes:\n",
    "        node_to_hoist = random.choice(internal_nodes)\n",
    "        return node_to_hoist.copy()\n",
    "    \n",
    "    return individual\n",
    "\n",
    "\n",
    "def expansion_mutation(parent, max_depth):\n",
    "    # Expansion Mutation: Replaces a leaf with a function node\n",
    "    individual = parent.copy()\n",
    "    all_nodes = individual.get_all_subtrees()\n",
    "    \n",
    "    leaf_nodes = [n for n in all_nodes if n.is_leaf()]\n",
    "    if leaf_nodes:\n",
    "        node_to_expand = random.choice(leaf_nodes)\n",
    "        func = random.choice(FUNCTION_SET)\n",
    "        arity = FUNCTION_METADATA[func]['arity']\n",
    "        node_to_expand.value = func\n",
    "        if arity == 1:\n",
    "            if random.random() < 0.5:\n",
    "                node_to_expand.left = Node(str(random.uniform(-1, 1)))\n",
    "            else:\n",
    "                node_to_expand.left = Node(random.choice(TERMINAL_SET))\n",
    "        else:\n",
    "            if random.random() < 0.5:\n",
    "                node_to_expand.left = Node(str(random.uniform(-1, 1)))\n",
    "            else:\n",
    "                node_to_expand.left = Node(random.choice(TERMINAL_SET))\n",
    "            if random.random() < 0.5:\n",
    "                node_to_expand.right = Node(str(random.uniform(-1, 1)))\n",
    "            else:\n",
    "                node_to_expand.right = Node(random.choice(TERMINAL_SET))\n",
    "            \n",
    "    return prune_tree(individual, max_depth)\n",
    "\n",
    "\n",
    "def collapse_mutation(parent, max_depth=None):\n",
    "    # Collapse Mutation: Replaces a function node with a leaf\n",
    "    individual = parent.copy()\n",
    "    all_nodes = individual.get_all_subtrees()\n",
    "    \n",
    "    internal_nodes = [n for n in all_nodes if not n.is_leaf()]\n",
    "    if internal_nodes:\n",
    "        node_to_collapse = random.choice(internal_nodes)\n",
    "        node_to_collapse.value = random.choice(TERMINAL_SET)\n",
    "        node_to_collapse.left = None\n",
    "        node_to_collapse.right = None\n",
    "        \n",
    "    return individual\n",
    "\n",
    "\n",
    "# Funzione per mutare un albero con uno dei 5 metodi\n",
    "def mutate(parent: Node, max_depth) -> Node:\n",
    "    mutation_functions = [\n",
    "        subtree_mutation, \n",
    "        point_mutation, \n",
    "        hoist_mutation, \n",
    "        expansion_mutation, \n",
    "        collapse_mutation\n",
    "    ]\n",
    "    \n",
    "    # Scegli una funzione di mutazione a caso e applicala\n",
    "    chosen_mutation = random.choice(mutation_functions)\n",
    "    return chosen_mutation(parent, max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Symbolic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genetic_programming(pop_size, max_generations, max_depth, xover_rate, mut_rate, limit_impr, elite_rate, imm_rate):\n",
    "    population = generate_population(pop_size, max_depth, x_train, y_train)\n",
    "    \n",
    "    best_individual_ever = None\n",
    "    best_fitness_ever = np.finfo(np.float64).max\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    elite_size = int(pop_size * elite_rate)\n",
    "    num_immigrants = int(pop_size * imm_rate)\n",
    "    \n",
    "    for gen in range(max_generations):\n",
    "        new_population = []\n",
    "        fitness_scores = []\n",
    "        pure_scores = []\n",
    "\n",
    "        for ind in population:\n",
    "            mse_score, raw_mse = calculate_fitness(ind, x_train, y_train)\n",
    "            fitness_scores.append(mse_score)\n",
    "            pure_scores.append(raw_mse)\n",
    "\n",
    "        # retian only sorted tree individuals, not the corresponding fitness\n",
    "        sorted_population = [ind for _, ind in sorted(zip(fitness_scores, population), key=lambda pair: pair[0])]\n",
    "\n",
    "        best_fitness_current_gen = sorted(pure_scores)[0]\n",
    "\n",
    "        if best_fitness_current_gen < best_fitness_ever:\n",
    "            best_fitness_ever = best_fitness_current_gen\n",
    "            best_individual_ever = sorted_population[0].copy()\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            \n",
    "        print(f\"Gen_{gen}: Best_MSE_so_far = {best_fitness_ever:.7f} | Best_Tree_so_far: {best_individual_ever}\")\n",
    "\n",
    "        if best_fitness_ever < 1e-10:\n",
    "            break\n",
    "\n",
    "        # Parent Selection: Over-selection\n",
    "        overselection_group1 = sorted_population[:elite_size] # Elite individuals\n",
    "        overselection_group2 = sorted_population[elite_size:] # Non-Elite individuals\n",
    "        \n",
    "        # Stagnation logic\n",
    "        if no_improvement_count >= limit_impr:\n",
    "            print(f\"Stagnazione rilevata.\")\n",
    "\n",
    "            # 1. Retain N best individuals\n",
    "            retained_size = 15\n",
    "            elite_group = overselection_group1[:retained_size]\n",
    "            new_population = [ind.copy() for ind in elite_group]\n",
    "\n",
    "            # 2. Immigration for the rest of the population\n",
    "            new_individuals_size = pop_size - len(new_population)\n",
    "            new_population.extend(generate_population(new_individuals_size, max_depth, x_train, y_train))\n",
    "\n",
    "            population = new_population\n",
    "            no_improvement_count = 0\n",
    "            continue\n",
    "\n",
    "        # Survivor Selection: Elitism\n",
    "        retained_size = int(len(overselection_group1) * 0.08)\n",
    "        elite_group = overselection_group1[:retained_size]\n",
    "        new_population = [ind.copy() for ind in elite_group]       \n",
    "\n",
    "        while len(new_population) < (pop_size - num_immigrants):\n",
    "            # Function to select a parent with Over-selection\n",
    "            def select_parent():\n",
    "                if random.random() < 0.8:\n",
    "                    return random.choice(overselection_group1)\n",
    "                else:\n",
    "                    return random.choice(overselection_group2)\n",
    "\n",
    "            # Select parents\n",
    "            parent1 = select_parent()\n",
    "            parent2 = select_parent()\n",
    "\n",
    "            # Perform either mutation or crossover\n",
    "            if random.random() < xover_rate:\n",
    "                child1, child2 = subtree_crossover(parent1, parent2)\n",
    "                # truncation after crossover\n",
    "                child1 = prune_tree(child1, max_depth)\n",
    "                child2 = prune_tree(child2, max_depth)\n",
    "            else:\n",
    "                child1 = parent1.copy()\n",
    "                child2 = parent2.copy()\n",
    "                \n",
    "            if random.random() < mut_rate:\n",
    "                child1 = mutate(child1, max_depth)\n",
    "            elif random.random() < mut_rate:\n",
    "                child2 = mutate(child2, max_depth)\n",
    "\n",
    "            # Simplification after crossover or mutation\n",
    "            child1 = simplify_tree(child1)\n",
    "            child2 = simplify_tree(child2)\n",
    "\n",
    "            # Child assessment and validation: Add your child only if his fitness is valid\n",
    "            for child in [child1, child2]:\n",
    "                if len(new_population) < (pop_size - num_immigrants):\n",
    "                    fitness, _ = calculate_fitness(child, x_train, y_train)\n",
    "\n",
    "                    if not np.isnan(fitness) and not np.isinf(fitness):\n",
    "                        new_population.append(child)\n",
    "\n",
    "        # Add IMMIGRANTS to the population to avoid getting stuck in local optima\n",
    "        new_population.extend(generate_population(num_immigrants, max_depth, x_train, y_train))\n",
    "\n",
    "        # Force mutation to all the best individuals every 10 generations to escape local optima\n",
    "        if (gen + 1) % 25 == 0:\n",
    "            print(f\"Gen_{gen}: Applico mutazione all'intera popolazione...\")\n",
    "            \n",
    "            for ind_to_mutate in elite_group:\n",
    "                original_fitness = fitness_scores[population.index(ind_to_mutate)]\n",
    "        \n",
    "                func_mutate = random.choice([point_mutation, subtree_mutation])\n",
    "                mutated_ind = func_mutate(ind_to_mutate, max_depth)\n",
    "                mutated_ind = simplify_tree(mutated_ind)\n",
    "                \n",
    "                mutated_fitness, _ = calculate_fitness(mutated_ind, x_train, y_train)\n",
    "                \n",
    "                if not np.isnan(mutated_fitness) and not np.isinf(mutated_fitness) and mutated_fitness < original_fitness:\n",
    "                    try:\n",
    "                        idx_in_new_pop = new_population.index(ind_to_mutate)\n",
    "                        new_population[idx_in_new_pop] = mutated_ind\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "        population = new_population\n",
    "        \n",
    "    return best_individual_ever, best_fitness_ever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R-squared value is a statistical metric that indicates the proportion of variance in the dependent variable that can be predicted \n",
    "# from the independent variable(s). R-squared measures how well a regression model fits the data.\n",
    "# - A value of 1 means the model explains 100% of the variability, while 0 means it explains nothing.\n",
    "def calculate_r_squared(y_true, y_pred):\n",
    "\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "\n",
    "    # dependent variable has no variability (it is costant!)\n",
    "    if ss_tot == 0:\n",
    "        # If the model predicts that constant perfectly\n",
    "        if np.allclose(y_true, y_pred): # returns True if all elements are enough close with a certain tolerance\n",
    "            r2 = 1.0\n",
    "        # If the model does NOT predict correctly\n",
    "        else:\n",
    "            r2 = 0.0\n",
    "    else:\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 1000\n",
    "if INPUT_VARS == 6:\n",
    "    MAX_DEPTH = 10\n",
    "    MAX_GENERATIONS = 2000\n",
    "else:\n",
    "    MAX_DEPTH = INPUT_VARS * 2 + 1\n",
    "    MAX_GENERATIONS = 3500\n",
    "PROB_CROSSOVER = 0.8\n",
    "PROB_MUTATION = 0.4\n",
    "MAX_NO_IMPROVEMENT_GENS = 15\n",
    "ELITE_RATE = 0.3\n",
    "IMMIGRANT_RATIO = 0.15\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Start Genetic Programming with Population {POP_SIZE} and Depth {MAX_DEPTH}\")\n",
    "    best_solution, best_fitness = genetic_programming(\n",
    "        POP_SIZE, \n",
    "        MAX_GENERATIONS, \n",
    "        MAX_DEPTH,\n",
    "        PROB_CROSSOVER,\n",
    "        PROB_MUTATION,\n",
    "        MAX_NO_IMPROVEMENT_GENS,\n",
    "        ELITE_RATE,\n",
    "        IMMIGRANT_RATIO,\n",
    "    )\n",
    "    \n",
    "    if best_solution:\n",
    "        print(\"\\n--- Final Results ---\")\n",
    "        \n",
    "        # Calculate the prediction on the training set\n",
    "        input_vars = {f'x{i}': x_train[:, i] for i in range(x_train.shape[1])}\n",
    "        y_pred_train = best_solution.evaluate(input_vars).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate the R-squared for the training set\n",
    "        r2_train = calculate_r_squared(y_train, y_pred_train)\n",
    "\n",
    "        print(f\"Best expression found: {best_solution}\")\n",
    "        print(f\"MSE on the training set: {best_fitness:.7f}\")\n",
    "        print(f\"R-squared on the training set: {r2_train:.7f}\")\n",
    "\n",
    "        if TRAIN_SIZE != 1.0:\n",
    "            # Calculate the prediction on the validation set\n",
    "            input_vars = {f'x{i}': x_val[:, i] for i in range(x_val.shape[1])}\n",
    "            y_pred_val = best_solution.evaluate(input_vars).reshape(-1, 1)\n",
    "\n",
    "            # Calculate the R-squared for the validation set\n",
    "            r2_val = calculate_r_squared(y_val, y_pred_val)\n",
    "\n",
    "            print(f\"MSE on the validation set: {calculate_fitness(best_solution, x_val, y_val)[1]:.7f}\")\n",
    "            print(f\"R-squared on the validation set: {r2_val:.7f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examples_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
